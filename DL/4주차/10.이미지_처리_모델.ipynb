{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "452978a7-0237-4a85-bdca-28a7008a6c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#10. 이미지 처리 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14e813ff-ee62-45db-b7a8-fc38b8b9bdc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN 기반 이미지 분류\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ddfd10a-d690-400d-a613-00ef33ef2171",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ResNet(Residual Network)\n",
    "# - ResNet은 매우 깊은 신경망을 학습할 수 있도록 설계된 아키텍처\n",
    "# - 잔차 연결을 도입하여, 기울기 소실 문제를 해결\n",
    "# - ResNet-50, ResNet-101, ResNet-152 등의 변형이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "814f9dd5-774b-4049-a411-e35598e718f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#VGG\n",
    "# - VGG는 작은 3x3 필터를 사용하여 깊이를 증가시킨 아키텍처\n",
    "# - VGG16과 VGG19가 대표적인 모델\n",
    "# - 단순하고 규칙적인 구조로 인해, 다양한 변형이 가능."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9dc757d7-522c-4294-bdb0-106f1070b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inception\n",
    "# - Inception은 다양한 크기의 필터를 병렬로 적용하여, 여러 수준의 특징을 추출\n",
    "# - Inception 모듈을 사용하여, 네트워크의 깊이와 너비를 동시에 확장\n",
    "# - GoogLeNet(Inception ㅍ1), Inception v2, Inception v3 등이 있음."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10df3b62-eeae-4082-a809-117fba1cc61b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6c44e44-d467-4684-b5ae-8c40b35f7549",
   "metadata": {},
   "outputs": [],
   "source": [
    "#객체 탐지(YOLO)\n",
    "# YOLO는 객체 탐지 모델로 이미지에서 객체의 위치와 클래스를 동시에 예측\n",
    "# YOLO는 이미지 전체를 한 번에 처리하여, 빠르고 정확한 객체 탐지를 수행."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ecddb21-6a13-4579-9f0f-b5791b0373f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO의 개녕\n",
    "#YOLO는 이미지를 SxS 그리드로 나누고, 각 그리드 셀에서 객체의 존재 여부를 예측\n",
    "# 각 그리드 셀은 B개의 바운딩 박스와 C개의 클래스 확률을 출력"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e450b82-dfbe-482e-9815-0f4aa927175e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#YOLO의 동작 원리\n",
    "#입력 이미지를 CNN을 통해 특징 맵으로 변환\n",
    "# 특징 맵을 SxS그리드로 나누고, 각 그리드 셀에서 바운딩 박스와 클래스 확률을 예측\n",
    "# 예측된 바운딩 박스와 클래스 확률을 바탕으로, 객체의 위치와 클래스를 결정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3111883a-42e9-47b7-b8e6-533aacaf24ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ceb4efb-6321-4cb1-8a80-05517b3a2a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지 세그멘테이션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "94e57a79-528c-469b-bc6a-06624906ebbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#이미지와 각 픽셀을 클래스 레이블로 분류하는 작업\n",
    "# 주로 시맨틱 세그멘테이션과 인스턴스 세그멘테이션 두 가지로 나뉨.\n",
    "\n",
    "#* 시멘틱 세그멘테이션 : 이미지의 각 픽셀을 클래스 레이블로 분류\n",
    "#* 인스턴스 세그멘테이션 : 시멘틱 세그멘테이션과 달리, 같은 클래스 내에서도 개별 객체를 구분"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cae8e064-98aa-4aff-be55-3103acbc08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 주요 세그멘테이션 모델\n",
    "#FCN(Fully Convolutional Network): 모든 레이어를 합성곱 레이어로 구성하여, 픽셀 단위의 예측을 수행\n",
    "#U-NET: U자형 구조를 가지며, 인코더-디코더 아키텍처를 사용하여 세그멘테이션을 수행\n",
    "#Mask R-CNN: 객체 탐지와 인스턴스 세그멘테이션을 동시에 수행하는 모델"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (DL_learn)",
   "language": "python",
   "name": "dl_learn"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
