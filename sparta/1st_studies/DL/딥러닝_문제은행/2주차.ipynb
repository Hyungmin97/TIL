{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ê¸°ë³¸ êµ¬ì¡°ë¥¼ í™œìš©í•œ ì œì•ˆ ëª¨ë¸ ì‘ì„±í•´ë³´ê¸°\n",
    "\n",
    "### ë¬¸ì œ\n",
    "- ì´ë¯¸ì§€ë¥¼ ì…ë ¥ìœ¼ë¡œ ë°›ì•„ í´ë˜ìŠ¤ë¥¼ ë¶„ë¥˜í•˜ëŠ” ëª¨ë¸ì„ Pytorchë¡œ êµ¬í˜„í•´ë³´ì„¸ìš”.\n",
    "- ì´ë¯¸ì§€ ë°ì´í„°ëŠ” 500x500ìœ¼ë¡œ ë³€í™˜í•´ì•¼í•´ìš”.\n",
    "- ì†ì‹¤ í•¨ìˆ˜ëŠ” êµì°¨ì—”íŠ¸ë¡œí”¼ ì†ì‹¤, ìµœì í™” í•¨ìˆ˜ëŠ” Adamì„ ì‚¬ìš©í•´ì•¼ í•©ë‹ˆë‹¤.\n",
    "- ì¶œë ¥ ë ˆì´ì–´ëŠ” Fully Connected\n",
    "\n",
    "### **ìˆ™ì œ ì •ë³´**\n",
    "\n",
    "â–  ë‚œì´ë„ : ğŸ”´ìƒ\n",
    "\n",
    "â–  ì‹¤ìŠµ ë²”ìœ„ : 2ì£¼ì°¨\n",
    "\n",
    "â–  ì‚¬ìš© ì–¸ì–´ ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ : pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¶ˆëŸ¬ì˜¤ê¸°\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim #ìµœì í™” í•¨ìˆ˜ë“¤ì„ í¬í•¨í•˜ê³  ìˆìœ¼ë©°, ì´ ì½”ë“œì—ì„œëŠ” Adamì„ ë¶ˆëŸ¬ì˜´\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ë°ì´í„° ì „ì²˜ë¦¬ ì„¤ì •\n",
    "# ì´ë¯¸ì§€ë¥¼ 500x500ìœ¼ë¡œ ë³€í™˜í•´ì•¼ í•˜ë¯€ë¡œ, torchvision.transformsë¥¼ ì‚¬ìš©í•´ ì´ë¯¸ì§€ë¥¼ 500x500ìœ¼ë¡œ ë¦¬ì‚¬ì´ì¦ˆí•˜ê³ , í…ì„œë¡œ ë³€í™˜\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((500,500)), #ì´ë¯¸ì§€ë¥¼ 500x500ìœ¼ë¡œ í¬ê¸° ì¡°ì ˆ\n",
    "    transforms.ToTensor() #ì´ë¯¸ì§€ë¥¼ PyTorch í…ì„œë¡œ ë³€í™˜, ì´ ê³¼ì •ì—ì„œ í”½ì…€ ê°’ì´ 0ê³¼ 1 ì‚¬ì´ë¡œ ì •ê·œí™”\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = datasets.FakeData(size = 1000, transform = transform, num_classes = 3)\n",
    "test_dataset = datasets.FakeData(size=200, transform=transform, num_classes=3)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32,shuffle=False)\n",
    "\n",
    "#datasets.FakeData: ì„ì˜ë¡œ ìƒì„±ëœ ë°ì´í„°ì…‹ì„ ë§Œë“¦. sizeëŠ” ë°ì´í„°ì…‹ í¬ê¸°, num_classesëŠ” ë¶„ë¥˜í•  í´ë˜ìŠ¤ ìˆ˜"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN ëª¨ë¸ ì •ì˜\n",
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleCNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
    "        self.fc1 = nn.Linear(64 * 125 * 125, 128)\n",
    "        self.fc2 = nn.Linear(128, 3)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 64 * 125 * 125)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "    \n",
    "        \n",
    "#ëª¨ë¸ ì´ˆê¸°í™”\n",
    "model = SimpleCNN()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ì†ì‹¤ í•¨ìˆ˜ì™€ ì˜µí‹°ë§ˆì´ì €\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 5.042930297553539\n",
      "Epoch 2, Loss: 1.0964488349854946\n",
      "Epoch 3, Loss: 1.0711977370083332\n",
      "Epoch 4, Loss: 0.7225117264315486\n",
      "Epoch 5, Loss: 0.19596216385252774\n",
      "Epoch 6, Loss: 0.03326049716270063\n",
      "Epoch 7, Loss: 0.007632721033587586\n",
      "Epoch 8, Loss: 0.0011785315709857969\n",
      "Epoch 9, Loss: 0.0004904147472188924\n",
      "Epoch 10, Loss: 0.00020744048015330918\n",
      "í•™ìŠµ ì¢…ë£Œ\n"
     ]
    }
   ],
   "source": [
    "#ëª¨ë¸ í›ˆë ¨\n",
    "\n",
    "#í›ˆë ¨ ë£¨í”„\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    running_loss = 0.0\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "    print(f'Epoch {epoch + 1}, Loss: {running_loss / len(train_loader)}')\n",
    "\n",
    "print(\"í•™ìŠµ ì¢…ë£Œ\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sparta)",
   "language": "python",
   "name": "sparta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
