{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f694094-5e6f-42ad-8f07-1b21b75ff75e",
   "metadata": {},
   "source": [
    "# Langchain과 FAISS를 이용한 실습"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ebe31bf-2d7e-4bdc-ae6f-1a26e5971d11",
   "metadata": {},
   "source": [
    "### 설치 및 기본 설정(터미널에서 진행)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2fad74c1-6237-48c3-9d76-77073baae57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install langchain langchain-openai faiss-cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c6b2095-3d75-4c10-a323-4fcec1ef528c",
   "metadata": {},
   "source": [
    "### OpenAI API 키 설정_환경변수엥서 API 키 가져오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1150df7d-0ba3-41d7-b0ee-4791aba7fdf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8df2b182-cc71-4d96-bcc2-bbc96f4577f5",
   "metadata": {},
   "source": [
    "## LangChain 기본 개념"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1610d04a-a530-4cb9-bb8c-625c2d9e7e7d",
   "metadata": {},
   "source": [
    "### 언어모델 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee9907f3-c5f4-4e0c-9425-c56d0af3ce2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "저는 AI입니다. 문장을 입력해주세요.\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "#모델 초기화\n",
    "model = ChatOpenAI(model='gpt-4')\n",
    "\n",
    "#모델에 메시지 전달\n",
    "response = model.invoke([HumanMessage(content='안녕하세요, 무엇을 도와드릴까요?')])\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930140e0-e7ea-4fbf-9595-978b1417689c",
   "metadata": {},
   "source": [
    "### 프롬프트 템플릿 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66bdc18c-5292-4b1d-9e5b-f312f7da28e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[SystemMessage(content='Translate the following sentence from English to korean:', additional_kwargs={}, response_metadata={}), HumanMessage(content='How are you?', additional_kwargs={}, response_metadata={})]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "#시스템 메시지 설정\n",
    "system_template = \"Translate the following sentence from English to {language}:\"\n",
    "\n",
    "#사용자 텍스트 입력\n",
    "prompt_template = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_template),\n",
    "    (\"user\", \"{text}\")\n",
    "])\n",
    "\n",
    "#프롬프트 생성\n",
    "result = prompt_template.invoke({\"language\": \"korean\", \"text\": \"How are you?\"})\n",
    "print(result.to_messages())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00e6dfcb-de90-4593-90d1-19588792186a",
   "metadata": {},
   "source": [
    "## LangChain Expression Language (LCEL)로 체인 연결"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0607f970-7733-48f1-8104-564f9dd92ca6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "도서관은 어디에 있나요?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "#응답을 파싱하는 파서 초기화\n",
    "parser = StrOutputParser()\n",
    "\n",
    "#템플릿, 모델, 파서를 체인으로 연결\n",
    "chain = prompt_template | model | parser\n",
    "\n",
    "#체인 실행\n",
    "response = chain.invoke({\"language\": \"korean\", \"text\": \"where is the library?\"})\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb50fa3a-9c15-42eb-9e59-a98b17c01052",
   "metadata": {},
   "source": [
    "## FAISS를 활용한 벡터 데이터베이스 구성 및 쿼리\n",
    "FAISS는 벡터 유사성 검색을 위한 라이브러리.\n",
    "\n",
    "***OpenAIEmbediings***로 텍스트를 벡터로 변환해 FAISS 인덱스에 저장."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f23ed1e-e3c6-46a7-b883-9e8bf59d6f4a",
   "metadata": {},
   "source": [
    "### Step 1: OpenAI 임베딩 모델로 벡터 임베딩 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b4dbad9-8316-49a2-8c97-7178f415fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import OpenAIEmbeddings\n",
    "\n",
    "#OpenAI 임베딩 모델 초기화\n",
    "embeddings = OpenAIEmbeddings(model=\"text-embedding-ada-002\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99490fdc-b54e-47ac-b43a-06c3985a0e04",
   "metadata": {},
   "source": [
    "### Step 2: FAISS 인덱스 초기화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9146bee-5a7b-4134-9361-2ebbceb722a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_community.docstore.in_memory import InMemoryDocstore\n",
    "\n",
    "#Faiss 인덱스 생성\n",
    "index = faiss.IndexFlatL2(len(embeddings.embed_query(\"hello world\")))\n",
    "vector_store = FAISS(\n",
    "    embedding_function=embeddings,\n",
    "    index=index,\n",
    "    docstore=InMemoryDocstore(),\n",
    "    index_to_docstore_id={}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02fa0243-ef40-45bc-849e-f59ddeed3827",
   "metadata": {},
   "source": [
    "### Step 3: 벡터 데이터베이스에 문서 추가"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c124e68e-00a1-4ba1-9cdf-332770a7afba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['5bc9c16a-b0ed-4a75-ac9a-8ebf8b88bd2a',\n",
       " '25e33f71-4529-4a51-ac86-460bc5a46be9',\n",
       " 'cc2dcde7-bdd8-4a46-83f4-b146205cb0c6',\n",
       " 'f1f5cab4-c9ab-4460-aecf-6047299a5010']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.documents import Document\n",
    "from uuid import uuid4\n",
    "\n",
    "#문서 생성\n",
    "documents = [\n",
    "    Document(page_content=\"LangChain을 사용해 프로젝트를 구축하고 있습니다!\", metadata={\"source\":\"tweet\"}),\n",
    "    Document(page_content=\"내일 날씨는 맑고 따뜻할 예정입니다.\", metadata={\"source\":\"news\"}),\n",
    "    Document(page_content=\"오늘 아침에는 팬케이크와 계란을 먹었어요.\", metadata={\"source\":\"personal\"}),\n",
    "    Document(page_content=\"주식 시장이 경기 침체 우려로 하락 중입니다.\", metadata={\"source\":\"news\"}),\n",
    "]\n",
    "\n",
    "#고유 ID 셍성 및 문서 추가\n",
    "uuids = [str(uuid4()) for _ in range(len(documents))]\n",
    "vector_store.add_documents(documents=documents, ids=uuids)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f608f8-ff43-4b2b-ad2e-be9e698b83aa",
   "metadata": {},
   "source": [
    "### Step4: 벡터 데이터베이스 쿼리"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "30752ac0-2805-41ae-8d48-4b3b90ea2709",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* 내일 날씨는 맑고 따뜻할 예정입니다. [{'source': 'news'}]\n",
      "* 주식 시장이 경기 침체 우려로 하락 중입니다. [{'source': 'news'}]\n",
      "* [SIM=0.159] LangChain을 사용해 프로젝트를 구축하고 있습니다! [{'source': 'tweet'}]\n"
     ]
    }
   ],
   "source": [
    "#기본 유사성 검색\n",
    "results = vector_store.similarity_search(\"내일 날씨는 어떨까요?\", k=2, filter={\"source\":\"news\"})\n",
    "for res in results:\n",
    "    print(f\"* {res.page_content} [{res.metadata}]\")\n",
    "\n",
    "#정수와 함꼐 유사성 검색\n",
    "results_with_scores = vector_store.similarity_search_with_score(\"LangChain에 대해 이야기해주세요.\", k=2, filter={\"source\":\"tweet\"})\n",
    "for res, score in results_with_scores:\n",
    "    print(f\"* [SIM={score:.3f}] {res.page_content} [{res.metadata}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeeb5ff7-ae84-4885-8c81-0594563c8d38",
   "metadata": {},
   "source": [
    "## RAG 체인에 FAISS 통합\n",
    "RAG 체인을 구성하여 검색된 문서를 바탕으로 질문에 응답할 수 있도록 구성"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86fff187-8149-4b05-92e4-4ad592b4f65b",
   "metadata": {},
   "source": [
    "### Step 1:  Retriever로 변환\n",
    "FAISS를 retriever로 변환해 RAG 체인에서 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88f059a5-3d3b-4d01-8760-4164dfc10930",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever(search_type=\"similarity\", search_kwargs={\"k\":1})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efdc9c91-aa74-4cf5-bb15-faaf4471a9dd",
   "metadata": {},
   "source": [
    "### Step 3: RAG 체인 생성\n",
    "LangChain의 모델과 프롬프트를 연결하여 RAG 체인을 구성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "75620729-56f5-4c25-ae85-36a00a6d4b20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Debug Output: 강사이름은?\n",
      "Debug Output: {'context': [Document(metadata={'source': 'news'}, page_content='내일 날씨는 맑고 따뜻할 예정입니다.')], 'question': '강사이름은?'}\n",
      "Final Response:\n",
      "The context does not provide information on the instructor's name.\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "# 프롬프트 템플릿 정의\n",
    "contextual_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Answer the question using only the following context.\"),\n",
    "    (\"user\", \"Context: {context}\\\\n\\\\nQuestion: {question}\")\n",
    "])\n",
    "\n",
    "\n",
    "class DebugPassThrough(RunnablePassthrough):\n",
    "    def invoke(self, *args, **kwargs):\n",
    "        output = super().invoke(*args, **kwargs)\n",
    "        print(\"Debug Output:\", output)\n",
    "        return output\n",
    "# 문서 리스트를 텍스트로 변환하는 단계 추가\n",
    "class ContextToText(RunnablePassthrough):\n",
    "    def invoke(self, inputs, config=None, **kwargs):  # config 인수 추가\n",
    "        # context의 각 문서를 문자열로 결합\n",
    "        context_text = \"\\n\".join([doc.page_content for doc in inputs[\"context\"]])\n",
    "        return {\"context\": context_text, \"question\": inputs[\"question\"]}\n",
    "\n",
    "# RAG 체인에서 각 단계마다 DebugPassThrough 추가\n",
    "rag_chain_debug = {\n",
    "    \"context\": retriever,                    # 컨텍스트를 가져오는 retriever\n",
    "    \"question\": DebugPassThrough()        # 사용자 질문이 그대로 전달되는지 확인하는 passthrough\n",
    "}  | DebugPassThrough() | ContextToText()|   contextual_prompt | model\n",
    "\n",
    "# 질문 실행 및 각 단계 출력 확인\n",
    "response = rag_chain_debug.invoke(\"강사이름은?\")\n",
    "print(\"Final Response:\")\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7107dd5b-9348-4011-8b3e-7cd59113db2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (sparta)",
   "language": "python",
   "name": "sparta"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
